<!doctype html><html lang=vi class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><link rel=icon href=../../../images/favicon.png type=image/png><title>:: Báo cáo thực tập</title>
<link href=../../../css/nucleus.css?1765297982 rel=stylesheet><link href=../../../css/fontawesome-all.min.css?1765297982 rel=stylesheet><link href=../../../css/hybrid.css?1765297982 rel=stylesheet><link href=../../../css/featherlight.min.css?1765297982 rel=stylesheet><link href=../../../css/perfect-scrollbar.min.css?1765297982 rel=stylesheet><link href=../../../css/auto-complete.css?1765297982 rel=stylesheet><link href=../../../css/atom-one-dark-reasonable.css?1765297982 rel=stylesheet><link href=../../../css/theme.css?1765297982 rel=stylesheet><link href=../../../css/hugo-theme.css?1765297982 rel=stylesheet><link href=../../../css/theme-workshop.css?1765297982 rel=stylesheet><script src=../../../js/jquery-3.3.1.min.js?1765297982></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=../../../vi/3-blogstranslated/3.2-blog2/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=../../../><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=../../../js/lunr.min.js?1765297982></script><script type=text/javascript src=../../../js/auto-complete.js?1765297982></script><script type=text/javascript>var baseurl="https://tranhoangtrunghieu.github.io/tranhoangtrunghieu-fcj-workshop//vi"</script><script type=text/javascript src=../../../js/search.js?1765297982></script></div><div class=highlightable><ul class=topics><li data-nav-id=/vi/1-worklog/ title=Worklog class=dd-item><a href=../../../vi/1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=../../../vi/1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=../../../vi/1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=../../../vi/1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.3-week3/ title="Worklog Tuần 3" class=dd-item><a href=../../../vi/1-worklog/1.3-week3/><b>1.3. </b>Worklog Tuần 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.4-week4/ title="Worklog Tuần 4" class=dd-item><a href=../../../vi/1-worklog/1.4-week4/><b>1.4. </b>Worklog Tuần 4
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.5-week5/ title="Worklog Tuần 5" class=dd-item><a href=../../../vi/1-worklog/1.5-week5/><b>1.5. </b>Worklog Tuần 5
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.6-week6/ title="Worklog Tuần 6" class=dd-item><a href=../../../vi/1-worklog/1.6-week6/><b>1.6. </b>Worklog Tuần 6
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.7-week7/ title="Worklog Tuần 7" class=dd-item><a href=../../../vi/1-worklog/1.7-week7/><b>1.7. </b>Worklog Tuần 7
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.9-week9/ title="Worklog Tuần 9" class=dd-item><a href=../../../vi/1-worklog/1.9-week9/><b>1.9. </b>Worklog Tuần 9
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=../../../vi/1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=../../../vi/1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/1-worklog/1.11-week11/ title="Worklog Tuần 11" class=dd-item><a href=../../../vi/1-worklog/1.11-week11/><b>1.11. </b>Worklog Tuần 11
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/2-proposal/ title="Bản đề xuất" class=dd-item><a href=../../../vi/2-proposal/><b>2. </b>Bản đề xuất
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/ title="Các bài blogs đã dịch" class="dd-item
parent"><a href=../../../vi/3-blogstranslated/><b>3. </b>Các bài blogs đã dịch
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/3-blogstranslated/3.1-blog1/ title="Blog 1" class=dd-item><a href=../../../vi/3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=../../../vi/3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/3-blogstranslated/3.2-blog2/ title class="dd-item
active"><a href=../../../vi/3-blogstranslated/3.2-blog2/><i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/4-eventparticipated/ title="Các events đã tham gia" class=dd-item><a href=../../../vi/4-eventparticipated/><b>4. </b>Các events đã tham gia
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/4-eventparticipated/4.1-event1/ title="AWS Cloud Day Vietnam - AI Edition 2025" class=dd-item><a href=../../../vi/4-eventparticipated/4.1-event1/><b>4.1. </b>AWS Cloud Day Vietnam - AI Edition 2025
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.2-event2/ title="Khám Phá Agentic AI – Workshop Amazon QuickSuite" class=dd-item><a href=../../../vi/4-eventparticipated/4.2-event2/><b>4.2. </b>Khám Phá Agentic AI – Workshop Amazon QuickSuite
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/4-eventparticipated/4.3-event3/ title="AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật" class=dd-item><a href=../../../vi/4-eventparticipated/4.3-event3/><b>4.3. </b>AWS Cloud Mastery Series #3 - Chuyên sâu về Trụ cột Bảo mật
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/ title=Workshop class=dd-item><a href=../../../vi/5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.2-auth-setup/ title="Cấu hình Google Cloud & Amazon Cognito" class=dd-item><a href=../../../vi/5-workshop/5.2-auth-setup/><b>5.1. </b>Cấu hình Google Cloud & Amazon Cognito
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.1-architecture/ title="Kiến trúc hệ thống & Luồng xác thực (Auth Flow)" class=dd-item><a href=../../../vi/5-workshop/5.1-architecture/><b>5.1. </b>Kiến trúc hệ thống & Luồng xác thực (Auth Flow)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.3-database/ title="Thiết kế Database (DynamoDB)" class=dd-item><a href=../../../vi/5-workshop/5.3-database/><b>5.3. </b>Thiết kế Database (DynamoDB)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-backend-logic/ title="Xây dựng API & Logic gửi Mail " class=dd-item><a href=../../../vi/5-workshop/5.4-backend-logic/><b>5.4. </b>Xây dựng API & Logic gửi Mail
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.4-backend-logic/5.4.1-event/ title=" CRUD Sự kiện (Event Handler)" class=dd-item><a href=../../../vi/5-workshop/5.4-backend-logic/5.4.1-event/><b>5.4.1. </b>CRUD Sự kiện (Event Handler)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-backend-logic/5.4.4-resend/ title="Cấu hình Resend & Route 53" class=dd-item><a href=../../../vi/5-workshop/5.4-backend-logic/5.4.4-resend/><b>5.4.0. </b>Cấu hình Resend & Route 53
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-backend-logic/5.4.2-todo/ title="CRUD Todo (Công việc)" class=dd-item><a href=../../../vi/5-workshop/5.4-backend-logic/5.4.2-todo/><b>5.4.2. </b>CRUD Todo (Công việc)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.4-backend-logic/5.4.3-sendreminder/ title="Gửi Thông Báo (Send Reminder)" class=dd-item><a href=../../../vi/5-workshop/5.4-backend-logic/5.4.3-sendreminder/><b>5.4.3. </b>Gửi Thông Báo (Send Reminder)
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/vi/5-workshop/5.5-frontend/ title=" Frontend & API Gateway" class=dd-item><a href=../../../vi/5-workshop/5.5-frontend/><b>5.6. </b>Frontend & API Gateway
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/vi/5-workshop/5.5-frontend/5.5.1-api/ title="Tạo API Gateway & Authen" class=dd-item><a href=../../../vi/5-workshop/5.5-frontend/5.5.1-api/><b>5.6.1. </b>Tạo API Gateway & Authen
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/5-workshop/5.5-frontend/5.5.2-amplify/-index/ title="Deploy Amplify & Tích hợp" class=dd-item><a href=../../../vi/5-workshop/5.5-frontend/5.5.2-amplify/-index/><b>5.6.2. </b>Deploy Amplify & Tích hợp <i class="fas fa-check read-icon"></i></a></li></ul></li></ul></li><li data-nav-id=/vi/6-self-evaluation/ title="Tự đánh giá" class=dd-item><a href=../../../vi/6-self-evaluation/><b>6. </b>Tự đánh giá
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/vi/7-feedback/ title="Chia sẻ, đóng góp ý kiến" class=dd-item><a href=../../../vi/7-feedback/><b>7. </b>Chia sẻ, đóng góp ý kiến
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=vi value=https://tranhoangtrunghieu.github.io/tranhoangtrunghieu-fcj-workshop/vi/3-blogstranslated/3.2-blog2/ selected>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=../../../vi/>Báo cáo thực tập</a> > <a href=../../../vi/3-blogstranslated/>Các bài blogs đã dịch</a> ></span></div><div class=progress><div class=wrapper><nav id=TableOfContents></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1></h1><p>AWS Compute Blog
Thiết Kế Các Mô Hình Tích Hợp Serverless Cho Mô Hình Ngôn Ngữ Lớn (LLMs)
Tác giả: Chris McPeek
Ngày đăng: 04 tháng 10, 2024
Danh mục: Amazon Bedrock, AWS Lambda, AWS Step Functions, Serverless
Bài viết này được viết bởi Josh Hart, Kiến Trúc Sư Giải Pháp Cấp Cao (Principal Solutions Architect) và Thomas Moore, Kiến Trúc Sư Giải Pháp Cấp Cao (Senior Solutions Architect).</p><p>Bài viết này khám phá các mô hình tích hợp theo thực tiễn tốt nhất để sử dụng các mô hình ngôn ngữ lớn (LLMs) trong các ứng dụng serverless. Những phương pháp tiếp cận này giúp tối ưu hiệu suất, sử dụng tài nguyên và khả năng phục hồi khi tích hợp các tính năng AI tạo sinh vào kiến trúc serverless của bạn.
Tổng quan về serverless, LLMs và ví dụ minh họa
Các tổ chức ở mọi quy mô đang khai thác các mô hình ngôn ngữ lớn (LLMs) để xây dựng các ứng dụng AI tạo sinh nhằm mang lại trải nghiệm khách hàng mới.
Các công nghệ serverless như AWS Lambda, AWS Step Functions và Amazon API Gateway cho phép bạn chuyển từ ý tưởng đến sản phẩm nhanh hơn mà không cần lo lắng về việc quản lý máy chủ.Mô hình tính phí theo mức sử dụng (pay-for-use) cũng giúp tăng tính linh hoạt với chi phí tối ưu.
Các ví dụ trong bài viết này sử dụng Amazon Bedrock, một dịch vụ được quản lý toàn phần cho phép truy cập các mô hình nền tảng foundation models Nguyên tắc tương tự cũng áp dụng cho các LLM được lưu trữ trên các nền tảng khác như Amazon SageMaker.
( FMs).Amazon Bedrock cho phép các nhà phát triển sử dụng LLM thông qua API mà không cần phải xử lý sự phức tạp của việc quản lý hạ tầng.Amazon SageMaker là một dịch vụ được quản lý toàn phần để xây dựng, huấn luyện và triển khai các mô hình học máy.</p><p>Trường hợp ví dụ trong bài viết này là sử dụng LLM để tạo ra nội dung marketing hấp dẫn cho việc ra mắt một dòng xe SUV gia đình mới.Các hình ảnh của phương tiện này được tạo sẵn bằng Amazon Titan Image Generator trong Amazon Bedrock, được minh họa bên dưới.</p><p>Hình ảnh ví dụ được tạo bằng Titan Image Generator
Khi các tổ chức áp dụng LLMs để cung cấp năng lực cho các ứng dụng AI tạo sinh (generative AI), kiến trúc serverless mang đến một phương pháp hấp dẫn cho phát triển nhanh và mở rộng quy mô tiết kiệm chi phí.Các phần tiếp theo sẽ trình bày một số mô hình tích hợp serverless nhằm xây dựng các ứng dụng AI tạo sinh có hiệu suất cao, chi phí tối ưu, và khả năng chịu lỗi tốt.</p><p>Gọi trực tiếp AWS Lambda</p><p>Gọi trực tiếp đến Amazon Bedrock từ AWS Lambda
Mô hình tích hợp serverless đơn giản nhất là gọi trực tiếp Bedrock trong Lambda bằng cách sử dụng AWS SDK. Dưới đây là ví dụ về một hàm Lambda sử dụng Python SDK (boto3), gọi đến API Bedrock InvokeModel.</p><p>python
import json
import boto3
brt = boto3.client(service_name=&lsquo;bedrock-runtime&rsquo;)</p><p>def lambda_handler(event, context):
body = json.dumps({
&ldquo;anthropic_version&rdquo;: &ldquo;bedrock-2023-05-31&rdquo;,
&ldquo;max_tokens&rdquo;: 1000,
&ldquo;messages&rdquo;: [{
&ldquo;role&rdquo;: &ldquo;user&rdquo;,
&ldquo;content&rdquo;: [{
&ldquo;type&rdquo;: &ldquo;text&rdquo;,
&ldquo;text&rdquo;:&ldquo;Create a 500 word car advert given these images and the following specification: \n {}".format(event[&lsquo;spec&rsquo;])
},
{
&ldquo;type&rdquo;: &ldquo;image&rdquo;,
&ldquo;source&rdquo;: {
&ldquo;type&rdquo;: &ldquo;base64&rdquo;,
&ldquo;media_type&rdquo;: &ldquo;image/jpeg&rdquo;,
&ldquo;data&rdquo;: event[&lsquo;image&rsquo;]
}
}]
}]
})</p><pre><code>modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'
accept = 'application/json'
contentType = 'application/json'
response = brt.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)
response_body = json.loads(response.get('body').read())

return {
    'statusCode': 200,
    'body': response_body[&quot;content&quot;][0][&quot;text&quot;]
}
</code></pre><p>Đoạn mã trên yêu cầu vai trò thực thi của hàm Lambda phải có quyền AWS Identity and Access Management (IAM) permissions to Amazon Bedrock, cụ thể là quyền hành động bedrock:InvokeModel.
Ví dụ này sử dụng mô hình ngôn ngữ lớn Anthropic Claude 3 Sonnet và Anthropic Claude Messages API cho phần payload.Lệnh gọi InvokeModel là đồng bộ, do đó nó sẽ chờ phản hồi từ LLM. Tùy thuộc vào mô hình và đoạn prompt, lệnh gọi có thể mất vài giây để hoàn thành. Hãy đảm bảo rằng thời gian chờ (timeout) của hàm Lambda được thiết lập phù hợp. Trong hầu hết các trường hợp, giá trị này cần được tăng lên so với mặc định là 3 giây.
Thư viện boto3 có thời gian chờ mặc định là 60 giây. Tùy vào trường hợp sử dụng, bạn có thể cần tăng thời gian chờ của client boto3, như được minh họa trong đoạn mã ví dụ bên dưới.
from botocore.config import Config</p><h1 id=set-the-read-timeout-to-600-seconds-10-minutes>Set the read timeout to 600 seconds (10 minutes)</h1><p>config = Config(read_timeout=600)</p><h1 id=create-the-bedrock-client-with-the-custom-read-timeout-configuration>Create the Bedrock client with the custom read timeout configuration</h1><p>boto3_bedrock = boto3.client(service_name=&lsquo;bedrock-runtime&rsquo;, config=config)
Khi làm việc với các mô hình ngôn ngữ lớn (LLMs), văn bản được tạo ra thường có dung lượng lớn, dẫn đến thời gian phản hồi tăng hoặc thậm chí bị hết thời gian chờ.Amazon Bedrock cung cấp khả năng truyền dữ liệu phản hồi theo luồng (streaming responses) bằng phương thức InvokeModelWithResponseStream, cho phép bạn xử lý và tiêu thụ phần văn bản được tạo ra theo từng khối (chunk) ngay khi nó sẵn sàng.Điều này giúp phản hồi nhanh hơn đến phía client và cho phép nhận được ít nhất một phần kết quả ngay cả khi xảy ra timeout.
Khi sử dụng phương thức truyền phản hồi theo luồng (response streaming) với các hàm Lambda, bạn nên đặt giá trị boto3 read_timeout thấp hơn thời gian chờ thực thi (execution timeout) của hàm. Điều này có nghĩa là bạn sẽ có tùy chọn trả về ít nhất một phần nội dung, trong một số trường hợp điều này vẫn tốt hơn là không có phản hồi nào cả.
Ví dụ, bạn có thể đặt thời gian chờ của hàm Lambda là 2 phút và thời gian chờ đọc của boto3 là 90 giây. Điều này cho phép bạn có thêm 30 giây để thực hiện các hành động bổ sung.
Tùy thuộc vào tình huống lỗi, bạn có thể thực hiện các hành động khác nhau:
Lỗi tạm thời như giới hạn tần suất (rate limiting) hoặc giới hạn dịch vụ (service quotas): Hãy xem xét việc giảm tần suất và thử lại yêu cầu, hoặc phân phối tải (load balancing) các yêu cầu sang khu vực khác bằng suy luận chéo vùng (cross-region inference).</p><p>Lỗi hết thời gian chờ (timeout) khi vượt quá giới hạn boto3 read_timeout: Quyết định xem có nên thử lại yêu cầu với prompt đơn giản hơn (hoặc rút ngắn độ dài phản hồi) hay chỉ trả về phản hồi một phần.
Liên kết chuỗi prompt với AWS Step Functions
Mô hình Lambda trực tiếp hoạt động hiệu quả đối với các trường hợp suy luận (inference) đơn giản chỉ có một prompt. Tuy nhiên, để thực hiện các tác vụ phức tạp hơn với LLM, cần sử dụng một kỹ thuật gọi là prompt chaining (liên kết chuỗi prompt), trong đó các tác vụ được chia nhỏ thành những prompt con có định nghĩa rõ ràng, và mỗi prompt sẽ được đưa vào LLM theo một trình tự xác định.
Việc thực hiện prompt chaining bên trong một hàm Lambda duy nhất có thể tốn nhiều thời gian và trong một số trường hợp có thể vượt quá giới hạn thời gian tối đa của Lambda là 15 phút. AWS Step Functions có thể được sử dụng để giải quyết vấn đề này bằng cách điều phối (orchestrate) các lệnh gọi đến LLM.Bedrock có tích hợp được tối ưu hóa(optimized intergration) cho Step Functions, cho phép bạn sử dụng chế độ Run as Job (.sync). Mô hình tích hợp này có nghĩa là Step Functions sẽ chờ cho đến khi yêu cầu InvokeModel hoàn tất trước khi chuyển sang trạng thái tiếp theo.Với Step Functions Standard Workflows, bạn chỉ phải trả phí cho mỗi lần chuyển trạng thái (state transition), điều này giúp giảm chi phí so với việc Lambda phải chờ trong trạng thái không hoạt động.
Ví dụ dưới đây minh họa cách liên kết chuỗi prompt với Step Functions chỉ bằng các tích hợp trực tiếp. Ví dụ này loại bỏ nhu cầu sử dụng mã tùy chỉnh trong Lambda.</p><p>Liên kết chuỗi prompt bằng AWS Step Functions
1.Dữ liệu đầu vào của người dùng (mô tả phương tiện) được truyền đến Amazon Bedrock thông qua tích hợp tối ưu (optimized intergration) của Step Functions.
2.Kết quả được tạo ra từ lệnh gọi API InvokeModel được truyền qua ResultPath đến bước kế tiếp.
3.Máy trạng thái (state machine) thiết lập đầu vào cho bước tiếp theo dựa trên đầu ra của bước trước đó bằng cách sử dụng Pass state.
4.Đầu ra của mỗi yêu cầu suy luận (inference request) tiếp tục được truyền giữa các bước trong quy trình làm việc (workflow).
5.Bước cuối cùng thực hiện một yêu cầu suy luận và kết quả cuối cùng được trả về như đầu ra của máy trạng thái.
Một lợi thế khác khi sử dụng AWS Step Functions để gọi LLM là cơ chế xử lý lỗi tích hợp sẵn. Step Functions có thể được thiết lập để tự động thử lại khi retry on error và cho phép bạn cấu hình tỷ lệ backoff cũng như thêm jitter để giúp kiểm soát việc giới hạn tần suất (throttling). Không cần viết mã tùy chỉnh nào.</p><p>Các tùy chọn xử lý lỗi tích hợp sẵn cho một hành động trong quy trình làm việc AWS Step Functions
Việc xử lý giới hạn tần suất (throttling) đặc biệt quan trọng khi bạn đang tiến gần đến các giới hạn dịch vụ (service quota) của Bedrock, chẳng hạn như số lượng yêu cầu được xử lý mỗi phút đối với một mô hình cụ thể.Hãy lưu ý rằng một số giới hạn là giới hạn cố định (hard limits) và không thể điều chỉnh.Tham khảo service quotas documation của Bedrock để biết thông tin mới nhất.
Chạy song song các prompt với AWS Step Functions
Hiệu suất của ứng dụng có thể được cải thiện bằng cách chia nhỏ các tác vụ thành các tác vụ con và chạy chúng song song.Điều này có thể làm giảm đáng kể tổng thời gian phản hồi, đặc biệt đối với các mô hình lớn và các prompt phức tạp.Trong ví dụ sau, việc xử lý song song đã giúp giảm tổng thời gian thực thi của máy trạng thái (state machine) từ 30,8 giây xuống còn 19,2 giây — tức là cải thiện 37,7% so với khi thực hiện các bước đó theo tuần tự.
Ví dụ bên dưới sử dụng trạng thái song song (parallel state) trong Step Functions để thực hiện các hành động InvokeModel của Bedrock đồng thời.</p><p>Ví dụ liên kết chuỗi prompt sử dụng trạng thái song song trong AWS Step Functions
1.Dữ liệu đầu vào của người dùng (mô tả phương tiện) được truyền đến Amazon Bedrock thông qua tích hợp tối ưu (optimized intergration) của Step Functions.
2.Trạng thái song song (parallel state) trong Step Functions cho phép sử dụng logic rẽ nhánh để thực hiện nhiều bước cùng lúc.
3.Các tác vụ suy luận (inference tasks) phức tạp được chạy song song nhằm giảm thời gian thực thi tổng thể từ đầu đến cuối.
4.Các tác vụ ngắn hơn có thể được kết hợp để cân bằng thời gian thực thi giữa các nhánh với những tác vụ có thời gian chạy dài hơn.
5.Kết quả được tạo ra được hợp nhất và phản hồi cuối cùng được trả về.
Ngoài trạng thái song song, Step Functions còn có trạng thái map (map state) cho phép chạy cùng một hành động nhiều lần song song với các đầu vào khác nhau.Ví dụ, nếu bạn muốn tạo tài liệu marketing cho 100 mẫu xe với dữ liệu được lưu trữ trong Amazon S3, bạn có thể chạy quy trình làm việc ở trên được lồng trong một trạng thái bản đồ phân tán (distributed map state).
Bộ nhớ đệm kết quả
Việc tạo văn bản bằng các mô hình ngôn ngữ lớn (LLMs) có thể tiêu tốn nhiều tài nguyên tính toán và thời gian, đặc biệt là đối với các prompt phức tạp hoặc các tác vụ tạo nội dung dài.Để cải thiện hiệu suất và giảm độ trễ, nên sử dụng cơ chế bộ nhớ đệm (caching) khi có thể bằng cách lưu trữ và tái sử dụng các phản hồi đã được tạo trước đó.hái niệm này được trình bày chi tiết trong bài viết Mastering LLM Caching for Next-Generation AI.
Bộ nhớ đệm có thể được triển khai ở nhiều cấp độ khác nhau trong kiến trúc ứng dụng của bạn, mỗi cấp độ đều có những ưu điểm và hạn chế riêng. Dưới đây là một số ví dụ:
1.Bộ nhớ đệm bên trong môi trường thực thi Lambda: nếu hàm Lambda của bạn nhận được các prompt hoặc đầu vào lặp lại, bạn có thể lưu trữ kết quả này trong bộ nhớ hoặc trong thư mục /tmp của môi trường thực thi đã được kích hoạt (warmed execution environment).
2.Dịch vụ bộ nhớ đệm bên ngoài: để vượt qua các giới hạn của bộ nhớ đệm trong bộ nhớ và tận dụng các giải pháp lưu trữ mạnh mẽ hơn, bạn có thể tích hợp với các dịch vụ bên ngoài để lưu trữ kết quả trước đó, chẳng hạn như Amazon ElastiCache (dành cho Redis hoặc Memcached) hoặc Amazon DynamoDB.
Ví dụ bên dưới sử dụng một quy trình làm việc Step Functions để kiểm tra phản hồi đã được lưu trong bộ nhớ đệm (cache) của DynamoDB trước khi gọi mô hình.Khóa bộ nhớ đệm (cache key) trong trường hợp này có thể là prompt được gửi đến LLM.Cách tiếp cận này giúp giảm chi phí đồng thời cải thiện hiệu suất.Ví dụ minh họa việc tạo ra các mô tả phương tiện tùy chỉnh dựa trên một nhóm đối tượng cụ thể (persona), chẳng hạn như tập trung vào các tính năng an toàn và không gian hành lý cho gia đình, hoặc các thông số hiệu suất dành cho người yêu thích thể thao tốc độ.</p><p>Ví dụ về AWS Step Functions sử dụng Amazon DynamoDB để lưu bộ nhớ đệm (cache) các phản hồi của LLM
Khi triển khai bộ nhớ đệm, điều quan trọng là phải xem xét các yếu tố như chiến lược làm mới bộ nhớ đệm (cache invalidation), giới hạn dung lượng bộ nhớ đệm, và yêu cầu về tính nhất quán của dữ liệu.Ví dụ, nếu mô hình LLM của bạn tạo ra nội dung động hoặc được cá nhân hóa, việc sử dụng bộ nhớ đệm có thể không phù hợp, vì các phản hồi có thể bị cũ hoặc không chính xác đối với những người dùng hoặc ngữ cảnh khác nhau.
Kết luận
Bài viết này đã khám phá các mô hình tích hợp để sử dụng LLM trong các ứng dụng serverless, nhằm mang lại trải nghiệm hiệu quả và đáng tin cậy cho thế hệ ứng dụng tiếp theo dành cho khách hàng.
Việc suy luận với một prompt duy nhất có thể được thực hiện bằng AWS Lambda thông qua AWS SDK.</p><p>Phản hồi từ các mô hình LLM có thể rất lớn và thường dẫn đến việc xử lý các đoạn văn bản lớn trong bộ nhớ, đặc biệt trong các trường hợp sử dụng
Retrieval-Augmented Generation (RAG).Do đó, việc lựa chọn cấu hình bộ nhớ tối ưu cho hàm Lambda là rất quan trọng, và cách được khuyến nghị để thực hiện điều này là sử dụng công cụ AWS Lambda Power Tuning.
Khi cần thực hiện các chuỗi prompt phức tạp hơn, thực tiễn tốt nhất là sử dụng Step Functions như một giải pháp để giảm thời gian chờ không hoạt động và tránh giới hạn thời gian tối đa 15 phút của Lambda.Step Functions cũng mang lại lợi ích của việc tích hợp được tối ưu hóa cho Bedrock, cũng như khả năng xử lý lỗi và chạy song song các tác vụ.
Hãy nhớ rằng việc lựa chọn mô hình (model choice) cũng là một yếu tố quan trọng cần cân nhắc để cân bằng giữa chi phí, hiệu suất và khả năng đầu ra.Chủ đề này được thảo luận chi tiết hơn trong bài viết Choose the best foundational model for your AI applications.
Để tìm hiểu thêm các mô hình serverless khác sử dụng Amazon Bedrock, hãy tham khảo Serverless Land.</p><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=../../../vi/3-blogstranslated/3.3-blog3/ title="Blog 3"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=../../../vi/4-eventparticipated/ title="Các events đã tham gia" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=../../../js/clipboard.min.js?1765297982></script><script src=../../../js/perfect-scrollbar.min.js?1765297982></script><script src=../../../js/perfect-scrollbar.jquery.min.js?1765297982></script><script src=../../../js/jquery.sticky.js?1765297982></script><script src=../../../js/featherlight.min.js?1765297982></script><script src=../../../js/highlight.pack.js?1765297982></script><script>hljs.initHighlightingOnLoad()</script><script src=../../../js/modernizr.custom-3.6.0.js?1765297982></script><script src=../../../js/learn.js?1765297982></script><script src=../../../js/hugo-learn.js?1765297982></script><link href=../../../mermaid/mermaid.css?1765297982 rel=stylesheet><script src=../../../mermaid/mermaid.js?1765297982></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>